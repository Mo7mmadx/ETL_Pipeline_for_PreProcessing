
##  ETL_Pipeline_for_PreProcessing


For this project, you'll be working with one dataset: event_data. The directory of CSV files partitioned by date. Here are examples of filepaths  in the dataset:

- ```event_data/2018-11-08-events.csv```
- ```event_data/2018-11-09-events.csv```



### Project Template

The project includes one Jupyter Notebook file, in which:

you will process the event_datafile_new.csv dataset to create a denormalized dataset
you will model the data tables keeping in mind the queries you need to run
you have been provided queries that you will need to model your data tables for
you will load the data into tables you create in Apache Cassandra and run your queries

